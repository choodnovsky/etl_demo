[2023-04-30 07:05:15,926] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [queued]>
[2023-04-30 07:05:16,214] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [queued]>
[2023-04-30 07:05:16,227] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-04-30 07:05:16,231] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-04-30 07:05:16,233] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-04-30 07:05:16,890] {taskinstance.py:1377} INFO - Executing <Task(S3DeleteObjectsOperator): delete_s3_obj> on 2023-04-29 00:00:00+00:00
[2023-04-30 07:05:16,992] {standard_task_runner.py:52} INFO - Started process 1185 to run task
[2023-04-30 07:05:17,028] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'dag_etl', 'delete_s3_obj', 'scheduled__2023-04-29T00:00:00+00:00', '--job-id', '85', '--raw', '--subdir', 'DAGS_FOLDER/dag_etl_taskflow.py', '--cfg-path', '/tmp/tmpbfl9j0zh', '--error-file', '/tmp/tmp3gf5_tqg']
[2023-04-30 07:05:17,064] {standard_task_runner.py:80} INFO - Job 85: Subtask delete_s3_obj
[2023-04-30 07:05:18,334] {task_command.py:370} INFO - Running <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [running]> on host 295d97741f96
[2023-04-30 07:05:20,637] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Victor
AIRFLOW_CTX_DAG_ID=dag_etl
AIRFLOW_CTX_TASK_ID=delete_s3_obj
AIRFLOW_CTX_EXECUTION_DATE=2023-04-29T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-29T00:00:00+00:00
[2023-04-30 07:05:20,901] {base.py:68} INFO - Using connection ID 'minio_conn' for task execution.
[2023-04-30 07:05:20,943] {base_aws.py:206} INFO - Credentials retrieved from login
[2023-04-30 07:05:24,944] {s3.py:841} INFO - Deleted: ['supermarket_sales.csv']
[2023-04-30 07:05:26,557] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=dag_etl, task_id=delete_s3_obj, execution_date=20230429T000000, start_date=20230430T070515, end_date=20230430T070526
[2023-04-30 07:05:27,043] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-04-30 07:05:27,824] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-05-02 10:34:48,917] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [queued]>
[2023-05-02 10:34:49,358] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [queued]>
[2023-05-02 10:34:49,361] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-05-02 10:34:49,366] {taskinstance.py:1357} INFO - Starting attempt 1 of 6
[2023-05-02 10:34:49,370] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-05-02 10:34:49,841] {taskinstance.py:1377} INFO - Executing <Task(S3DeleteObjectsOperator): delete_s3_obj> on 2023-04-29 00:00:00+00:00
[2023-05-02 10:34:49,906] {standard_task_runner.py:52} INFO - Started process 701 to run task
[2023-05-02 10:34:50,002] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'dag_etl', 'delete_s3_obj', 'scheduled__2023-04-29T00:00:00+00:00', '--job-id', '406', '--raw', '--subdir', 'DAGS_FOLDER/dag_etl_taskflow.py', '--cfg-path', '/tmp/tmpsgh6_s08', '--error-file', '/tmp/tmpwq1w246p']
[2023-05-02 10:34:50,021] {standard_task_runner.py:80} INFO - Job 406: Subtask delete_s3_obj
[2023-05-02 10:34:51,171] {task_command.py:370} INFO - Running <TaskInstance: dag_etl.delete_s3_obj scheduled__2023-04-29T00:00:00+00:00 [running]> on host 295d97741f96
[2023-05-02 10:34:53,907] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Victor
AIRFLOW_CTX_DAG_ID=dag_etl
AIRFLOW_CTX_TASK_ID=delete_s3_obj
AIRFLOW_CTX_EXECUTION_DATE=2023-04-29T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-04-29T00:00:00+00:00
[2023-05-02 10:34:54,098] {base.py:68} INFO - Using connection ID 'minio_conn' for task execution.
[2023-05-02 10:34:54,104] {base_aws.py:206} INFO - Credentials retrieved from login
[2023-05-02 10:34:56,950] {s3.py:841} INFO - Deleted: ['supermarket_sales.csv']
[2023-05-02 10:34:57,350] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=dag_etl, task_id=delete_s3_obj, execution_date=20230429T000000, start_date=20230502T103448, end_date=20230502T103457
[2023-05-02 10:34:57,949] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-05-02 10:34:58,961] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
